{
    "docs": [
        {
            "location": "/",
            "text": "PyJet: The Python Deep Learning library\n\n\n\n\nInstallation\n\n\nTo install run the following in your HOME directory.\n\n\ngit clone https://github.com/abhmul/PyJet/\ncd PyJet\nsudo pip install -e .\ncd ..\n\n\n\n\nUpdate\n\n\nTo update, go to your PyJet installation directory (should be HOME/PyJet if you followed the installation instructions) and run\n\n\ngit pull",
            "title": "Home"
        },
        {
            "location": "/#pyjet-the-python-deep-learning-library",
            "text": "",
            "title": "PyJet: The Python Deep Learning library"
        },
        {
            "location": "/#installation",
            "text": "To install run the following in your HOME directory.  git clone https://github.com/abhmul/PyJet/\ncd PyJet\nsudo pip install -e .\ncd ..",
            "title": "Installation"
        },
        {
            "location": "/#update",
            "text": "To update, go to your PyJet installation directory (should be HOME/PyJet if you followed the installation instructions) and run  git pull",
            "title": "Update"
        },
        {
            "location": "/models/SLModel/",
            "text": "cast_input_to_torch\n\n\ncast_input_to_torch(self, x, volatile=False)\n\n\n\n\n\n\ncast_target_to_torch\n\n\ncast_target_to_torch(self, y, volatile=False)\n\n\n\n\n\n\ncast_output_to_numpy\n\n\ncast_output_to_numpy(self, preds)\n\n\n\n\n\n\nforward\n\n\nforward(self)\n\n\n\n\n\n\ntrain_on_batch\n\n\ntrain_on_batch(self, x, target, optimizer, loss_fn, metrics=())\n\n\n\n\n\n\nvalidate_on_batch\n\n\nvalidate_on_batch(self, x, target, metrics)\n\n\n\n\n\n\npredict_on_batch\n\n\npredict_on_batch(self, x)\n\n\n\n\n\n\nfit_generator\n\n\nfit_generator(self, generator, steps_per_epoch, epochs, optimizer, loss_fn, validation_generator=None, validation_steps=0, metrics=(), callbacks=(), initial_epoch=0)\n\n\n\n\n\n\nvalidate_generator\n\n\nvalidate_generator(self, val_generator, validation_steps, loss_fn=None, metrics=())\n\n\n\n\n\n\npredict_generator\n\n\npredict_generator(self, generator, prediction_steps, verbose=0)\n\n\n\n\n\n\nload_state\n\n\nload_state(self, load_path)\n\n\n\n\n\n\nsave_state\n\n\nsave_state(self, save_path)",
            "title": "SLModel"
        },
        {
            "location": "/layers/core/",
            "text": "[source]\n\n\nFullyConnected\n\n\npyjet.layers.FullyConnected(input_size, output_size, use_bias=True, activation='linear', num_layers=1, batchnorm=False, input_dropout=0.0, dropout=0.0)\n\n\n\n\nJust your regular fully-connected NN layer.\n\nFullyConnected\n implements the operation:\n\noutput = activation(dot(input, kernel) + bias)\n\nwhere \nactivation\n is the element-wise activation function\npassed as the \nactivation\n argument, \nkernel\n is a weights matrix\ncreated by the layer, and \nbias\n is a bias vector created by the layer\n(only applicable if \nuse_bias\n is \nTrue\n).\n- \nNote\n: if the input to the layer has a rank greater than 2, then\nit is flattened prior to the initial dot product with \nkernel\n.\n\nExample\n\n\n# A layer that takes as input tensors of shape (*, 128)\n# and outputs arrays of shape (*, 64)\nlayer = FullyConnected(128, 64)\ntensor = torch.randn(32, 128)\noutput = layer(tensor)\n\n\n\n\nArguments\n\n\n\n\ninput_size\n: Positive integer, dimensionality of the input space.\n\n\noutput_size\n: Positive integer, dimensionality of the input space.\n\n\nactivation\n: String, Name of activation function to use\n(supports \"tanh\", \"relu\", and \"linear\").\nIf you don't specify anything, no activation is applied\n(ie. \"linear\" activation: \na(x) = x\n).\n\n\nuse_bias\n: Boolean, whether the layer uses a bias vector.\n\nInput shape\n\n\n\n\n2D tensor with shape: \n(batch_size, input_size)\n.\n\nOutput shape\n\n\n2D tensor with shape: \n(batch_size, output_size)\n.\n\n\n\n\n[source]\n\n\nFlatten\n\n\npyjet.layers.Flatten()\n\n\n\n\nFlattens the input. Does not affect the batch size.\n\nExample\n\n\nflatten = Flatten()\ntensor = torch.randn(32, 2, 3)\n# The output will be of shape (32, 6)\noutput = flatten(tensor)",
            "title": "Core Layers"
        },
        {
            "location": "/layers/convolutional/",
            "text": "[source]\n\n\nConv1D\n\n\npyjet.layers.Conv1D(input_size, output_size, kernel_size, stride=1, padding='same', dilation=1, groups=1, use_bias=True, activation='linear', num_layers=1, batchnorm=False, input_dropout=0.0, dropout=0.0)\n\n\n\n\n\n\n[source]\n\n\nConv2D\n\n\npyjet.layers.Conv2D(input_size, output_size, kernel_size, stride=1, padding='same', dilation=1, groups=1, use_bias=True, activation='linear', num_layers=1, batchnorm=False, input_dropout=0.0, dropout=0.0)\n\n\n\n\n\n\n[source]\n\n\nConv3D\n\n\npyjet.layers.Conv3D(input_size, output_size, kernel_size, stride=1, padding='same', dilation=1, groups=1, use_bias=True, activation='linear', num_layers=1, batchnorm=False, input_dropout=0.0, dropout=0.0)",
            "title": "Convolutional Layers"
        },
        {
            "location": "/layers/recurrent/",
            "text": "[source]\n\n\nSimpleRNN\n\n\npyjet.layers.SimpleRNN(input_size, output_size, num_layers=1, bidirectional=False, input_dropout=0.0, dropout=0.0, nonlinearity='tanh', return_sequences=False, return_state=False)\n\n\n\n\n\n\n[source]\n\n\nGRU\n\n\npyjet.layers.GRU(input_size, output_size, num_layers=1, bidirectional=False, input_dropout=0.0, dropout=0.0, return_sequences=False, return_state=False)\n\n\n\n\n\n\n[source]\n\n\nLSTM\n\n\npyjet.layers.LSTM(input_size, output_size, num_layers=1, bidirectional=False, input_dropout=0.0, dropout=0.0, return_sequences=False, return_state=False)",
            "title": "Recurrent Layers"
        },
        {
            "location": "/layers/functions/",
            "text": "pad_tensor\n\n\npyjet.layers.pad_tensor(tensor, length, pad_value=0.0, dim=0)\n\n\n\n\n\n\npad_sequences\n\n\npyjet.layers.pad_sequences(tensors, pad_value=0.0, length_last=False)\n\n\n\n\n\n\nunpad_sequences\n\n\npyjet.layers.unpad_sequences(padded_tensors, seq_lens, length_last=False)\n\n\n\n\n\n\npack_sequences\n\n\npyjet.layers.pack_sequences(tensors)\n\n\n\n\n\n\nunpack_sequences\n\n\npyjet.layers.unpack_sequences(packed_tensors, seq_lens)\n\n\n\n\n\n\nkmax_pooling\n\n\npyjet.layers.kmax_pooling(x, dim, k)\n\n\n\n\n\n\npad_numpy_to_length\n\n\npyjet.layers.pad_numpy_to_length(x, length)\n\n\n\n\n\n\nseq_softmax\n\n\npyjet.layers.seq_softmax(x, return_padded=False)",
            "title": "Functions"
        },
        {
            "location": "/data/",
            "text": "[source]\n\n\nDataset\n\n\npyjet.data.Dataset()\n\n\n\n\nAn abstract container for data designed to be passed to a model.\nThis container should implement create_batch. It is only necessary\nto implement validation_split() if you use this module to split your\ndata into a train and test set. Same goes for kfold()\n\n\n\n\n_Note\n_:\n\n\n\n\nThough not forced, a Dataset is really a constant object. Once created,\nit should not be mutated in any way.\n\n\n\n\n[source]\n\n\nNpDataset\n\n\npyjet.data.NpDataset(x, y=None)\n\n\n\n\nA Dataset that is built from numpy data.\n\n\nArguments\n\n\nx -- The input data as a numpy array\ny -- The target data as a numpy array (optional)\n\n\n\n\n[source]\n\n\nHDF5Dataset\n\n\npyjet.data.HDF5Dataset(x, y=None)\n\n\n\n\n\n\n[source]\n\n\nTorchDataset\n\n\npyjet.data.TorchDataset(x, y=None)\n\n\n\n\n\n\n[source]\n\n\nDatasetGenerator\n\n\npyjet.data.DatasetGenerator(dataset, steps_per_epoch=None, batch_size=None, shuffle=True, seed=None)\n\n\n\n\nAn iterator to create batches for a model using a Dataset. 2 of the\nfollowing must be defined\n-- The input Dataset's length\n-- steps_per_epoch\n-- batch_size\nAlso, if the Dataset's length is not defined, its create_batch method\nshould not take any inputs\n\n\nArguments\n\n\ndataset -- the dataset to generate from\nsteps_per_epoch -- The number of iterations in one epoch (optional)\nbatch_size -- The number of samples in one batch (optional)\nshuffle -- Whether or not to shuffle the dataset before each epoch\n- \ndefault\n: True\nseed -- A seed for the random number generator (optional).",
            "title": "Data"
        },
        {
            "location": "/losses/",
            "text": "bce_with_logits\n\n\nbce_with_logits(outputs, targets, size_average=True)\n\n\n\n\nComputes the binary cross entropy between targets and output's logits.\n\n\nSee :class:\n~torch.nn.BCEWithLogitsLoss\n for details.\n\n\nArguments\n\n\noutputs -- A torch FloatTensor of arbitrary shape with a 1 dimensional channel axis\ntargets -- A binary torch LongTensor of the same size without the channel axis\nsize_average -- By default, the losses are averaged over observations for each minibatch.\nHowever, if the field size_average is set to False, the losses are instead\nsummed for each minibatch.\n- \n_Returns\n_:\n\n\nA scalar tensor equal to the total loss of the output.\n\n\n\n\nExamples:\n:\n\n\n\n\n\n\n\n\n\n\ninput = autograd.Variable(torch.randn(3), requires_grad=True)\ntarget = autograd.Variable(torch.FloatTensor(3).random_(2))\nloss = bce_with_logits(input, target)\nloss.backward()\n\n\n\n\n\n\n\n\n\n\ncategorical_crossentropy\n\n\ncategorical_crossentropy(outputs, targets, size_average=True)\n\n\n\n\nComputes the categorical crossentropy loss over some outputs and targets according the\nequation for the ith output\n\n\n-log(output[target])\n\n\nand is accumulated with a sum or average over all outputs.\n\n\n\n\n_Arguments\n_:\n\n\n\n\noutputs -- The torch FloatTensor output from a model with the shape (N, C) where N is the\nnumber of outputs and C is the number of classes.\ntargets -- The torch LongTensor indicies of the ground truth with the shape (N,) where N is\nthe number of outputs and each target t is 0 <= t < C.\nsize_average -- By default, the losses are averaged over observations for each minibatch.\nHowever, if the field size_average is set to False, the losses are instead\nsummed for each minibatch.\n- \n_Returns\n_:\n\n\nA scalar tensor equal to the total loss of the output.",
            "title": "Losses"
        },
        {
            "location": "/metrics/",
            "text": "topk_accuracy\n\n\ntopk_accuracy(output, target, topk)\n\n\n\n\nComputes the precision@k for the specified values of k\n\n\nArguments\n\n\noutputs -- A torch FloatTensor of arbitrary shape\ntargets -- A torch LongTensor of the same size except along\nthe channels dimension (the target dimension - 1)\ntopk -- The k to compute the topk accuracy for\n- \n_Returns\n_:\n\n\nA scalar tensor equal to the topk accuracy of the output\n\n\n\n\naccuracy\n\n\naccuracy(output, target)",
            "title": "Metrics"
        },
        {
            "location": "/callbacks/",
            "text": "[source]\n\n\nMetricLogger\n\n\npyjet.callbacks.MetricLogger(log_fname)\n\n\n\n\n\n\n[source]\n\n\nModelCheckpoint\n\n\npyjet.callbacks.ModelCheckpoint(filepath, monitor, monitor_val=True, verbose=0, save_best_only=False, mode='auto', period=1)\n\n\n\n\nSave the model after every epoch.\n\nfilepath\n can contain named formatting options,\nwhich will be filled the value of \nepoch\n and\nkeys in \nlogs\n (passed in \non_epoch_end\n).\nFor example: if \nfilepath\n is \nweights.{epoch:02d}-{val_loss:.2f}.hdf5\n,\nthen the model checkpoints will be saved with the epoch number and\nthe validation loss in the filename.\n\nArguments\n\n\n\n\nfilepath\n: string, path to save the model file.\n\n\nmonitor\n: quantity to monitor.\n\n\nverbose\n: verbosity mode, 0 or 1.\n\n\nsave_best_only\n: if \nsave_best_only=True\n,\nthe latest best model according to\nthe quantity monitored will not be overwritten.\n\n\nmode\n: one of {auto, min, max}.\nIf \nsave_best_only=True\n, the decision\nto overwrite the current save file is made\nbased on either the maximization or the\nminimization of the monitored quantity. For \nval_acc\n,\nthis should be \nmax\n, for \nval_loss\n this should\nbe \nmin\n, etc. In \nauto\n mode, the direction is\nautomatically inferred from the name of the monitored quantity.\n\n\nsave_weights_only\n: if True, then only the model's weights will be\nsaved (\nmodel.save_weights(filepath)\n), else the full model\nis saved (\nmodel.save(filepath)\n).\n\n\nperiod\n: Interval (number of epochs) between checkpoints.\n\n\n\n\n\n\n[source]\n\n\nPlotter\n\n\npyjet.callbacks.Plotter(monitor, scale='linear', plot_during_train=True, save_to_file=None, block_on_end=True)\n\n\n\n\n\n\n[source]\n\n\nCallback\n\n\npyjet.callbacks.Callback()\n\n\n\n\nAbstract base class used to build new callbacks.\n\nProperties\n\n\n\n\nparams\n: dict. Training parameters\n(eg. verbosity, batch size, number of epochs...).\n\n\nmodel\n: instance of \nkeras.models.Model\n.\nReference of the model being trained.\nThe \nlogs\n dictionary that callback methods\ntake as argument will contain keys for quantities relevant to\nthe current batch or epoch.\nCurrently, the \n.fit()\n method of the \nSequential\n model class\nwill include the following quantities in the \nlogs\n that\nit passes to its callbacks:\n\n\non_epoch_end\n: logs include \nacc\n and \nloss\n, and\noptionally include \nval_loss\n\n(if validation is enabled in \nfit\n), and \nval_acc\n\n(if validation and accuracy monitoring are enabled).\n\n\non_batch_begin\n: logs include \nsize\n,\nthe number of samples in the current batch.\n\n\non_batch_end\n: logs include \nloss\n, and optionally \nacc\n\n(if accuracy monitoring is enabled).",
            "title": "Callbacks"
        },
        {
            "location": "/preprocessing/image/",
            "text": "[source]\n\n\nImageDataGenerator\n\n\npyjet.preprocessing.image.ImageDataGenerator(generator, labels=True, augment_masks=True, samplewise_center=False, samplewise_std_normalization=False, rotation_range=0.0, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0, fill_mode='nearest', cval=0.0, horizontal_flip=False, vertical_flip=False, rescale=None, preprocessing_function=None, seed=None, data_format='channels_last')\n\n\n\n\nGenerate minibatches of image data with real-time data augmentation.\n\nArguments\n\n\n\n\nsamplewise_center\n: set each sample mean to 0.\n\n\nsamplewise_std_normalization\n: divide each input by its std.\n\n\nrotation_range\n: degrees (0 to 180).\n\n\nwidth_shift_range\n: fraction of total width.\n\n\nheight_shift_range\n: fraction of total height.\n\n\nshear_range\n: shear intensity (shear angle in radians).\n\n\nzoom_range\n: amount of zoom. if scalar z, zoom will be randomly picked\nin the range [1-z, 1+z]. A sequence of two can be passed instead\nto select this range.\n\n\nchannel_shift_range\n: shift range for each channels.\n\n\nfill_mode\n: points outside the boundaries are filled according to the\ngiven mode ('constant', 'nearest', 'reflect' or 'wrap'). Default\nis 'nearest'.\n\n\ncval\n: value used for points outside the boundaries when fill_mode is\n'constant'. Default is 0.\n\n\nhorizontal_flip\n: whether to randomly flip images horizontally.\n\n\nvertical_flip\n: whether to randomly flip images vertically.\n\n\nrescale\n: rescaling factor. If None or 0, no rescaling is applied,\notherwise we multiply the data by the value provided. This is\napplied after the \npreprocessing_function\n (if any provided)\nbut before any other transformation.\n\n\npreprocessing_function\n: function that will be implied on each input.\nThe function will run before any other modification on it.\nThe function should take one argument:\none image (Numpy tensor with rank 3),\nand should output a Numpy tensor with the same shape.\n\n\ndata_format\n: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n(the depth) is at index 1, in 'channels_last' mode it is at index 3.\nIt defaults to \"channels_last\".\n\n\n\n\n\n\nstandardize\n\n\nstandardize(self, x)\n\n\n\n\nApply the normalization configuration to a batch of inputs.\n\nArguments\n\n\n\n\nx\n: batch of inputs to be normalized.\n\nReturns\n\n\n\n\nThe inputs, normalized.\n\n\n\n\nrandom_transform\n\n\nrandom_transform(self, x, seed=None)\n\n\n\n\nRandomly augment a single image tensor.\n\nArguments\n\n\n\n\nx\n: 3D tensor, single image.\n\n\nseed\n: random seed.\n\nReturns\n\n\n\n\nA randomly transformed version of the input (same shape).",
            "title": "Image"
        },
        {
            "location": "/backend/",
            "text": "cudaLongTensor\n\n\nbackend.cudaLongTensor(x)\n\n\n\n\n\n\ncudaByteTensor\n\n\nbackend.cudaByteTensor(x)\n\n\n\n\n\n\ncudaZeros\n\n\nbackend.cudaZeros()\n\n\n\n\n\n\ncudaOnes\n\n\nbackend.cudaOnes()\n\n\n\n\n\n\nflatten\n\n\nbackend.flatten(x)\n\n\n\n\nFlattens along axis 0 (# rows in == # rows out)\n\n\nsoftmax\n\n\nbackend.softmax(x)\n\n\n\n\n\n\nzero_center\n\n\nbackend.zero_center(x)\n\n\n\n\n\n\nstandardize\n\n\nbackend.standardize(x)\n\n\n\n\n\n\nfrom_numpy\n\n\nbackend.from_numpy(x)\n\n\n\n\n\n\nto_numpy\n\n\nbackend.to_numpy(x)\n\n\n\n\n\n\ncudaFloatTensor\n\n\nbackend.cudaFloatTensor(x)",
            "title": "Backend"
        },
        {
            "location": "/backend/#flattens-along-axis-0-rows-in-rows-out",
            "text": "softmax  backend.softmax(x)   zero_center  backend.zero_center(x)   standardize  backend.standardize(x)   from_numpy  backend.from_numpy(x)   to_numpy  backend.to_numpy(x)   cudaFloatTensor  backend.cudaFloatTensor(x)",
            "title": "Flattens along axis 0 (# rows in == # rows out)"
        }
    ]
}